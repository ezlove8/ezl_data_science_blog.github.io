{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Ada Boost Classification Model (from scratch)\n",
    "There are many packages that include wonderful pre-built functions to build adaboost models. I figured a good way to really learn and appreciate the algorithm though would be to build one from scratch using (mostly) base python :)\n",
    "\n",
    "##A couple of notes:\n",
    "-there is likely some redundant/inefficient code in here! I really tried to only use native python so there is going to be some silly work arounds in here. Also expect a lot of if/for/while statements\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Reading in data\n",
    "this data set is a pretty simple data set of patient data collected to try and predict two outcomes: inflammation and nephiritis. For this project we will just focus on inflammation as the primary outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>nausea</th>\n",
       "      <th>lumbar_pain</th>\n",
       "      <th>urine_pushing</th>\n",
       "      <th>micturition</th>\n",
       "      <th>burning</th>\n",
       "      <th>inflammation</th>\n",
       "      <th>nephritis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35.9</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp nausea lumbar_pain urine_pushing micturition burning inflammation  \\\n",
       "0  35.5     no         yes            no          no      no           no   \n",
       "1  35.9     no          no           yes         yes     yes          yes   \n",
       "2  35.9     no         yes            no          no      no           no   \n",
       "3  36.0     no          no           yes         yes     yes          yes   \n",
       "4  36.0     no         yes            no          no      no           no   \n",
       "\n",
       "  nephritis  \n",
       "0        no  \n",
       "1        no  \n",
       "2        no  \n",
       "3        no  \n",
       "4        no  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"diagnosis.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 cleaning data and adding initial sample weights \n",
    "'temp' is the only continuous variable in this dataset, the rest can be convirted to binary dummy variables (rather than characters. \n",
    "\n",
    "At first, all samples will be equally weighted (1/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temp  nausea  lumbar_pain  urine_pushing  micturition  burning  \\\n",
      "0  35.5       0            1              0            0        0   \n",
      "1  35.9       0            0              1            1        1   \n",
      "2  35.9       0            1              0            0        0   \n",
      "3  36.0       0            0              1            1        1   \n",
      "4  36.0       0            1              0            0        0   \n",
      "\n",
      "   inflammation  nephritis    weight  \n",
      "0             0          0  0.008333  \n",
      "1             1          0  0.008333  \n",
      "2             0          0  0.008333  \n",
      "3             1          0  0.008333  \n",
      "4             0          0  0.008333  \n"
     ]
    }
   ],
   "source": [
    "def clean_data(obs):\n",
    "    if obs == 'yes':\n",
    "        new_obs = 1\n",
    "    elif obs == 'no':\n",
    "        new_obs = 0\n",
    "    else:\n",
    "        new_obs = obs\n",
    "    return new_obs\n",
    "\n",
    "df_nonclean = pd.DataFrame.copy(df)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: clean_data(x))\n",
    "df['weight'] = 1/len(df)\n",
    "print(df.head())\n",
    "\n",
    "df1 = pd.DataFrame.copy(df) #making a copy so that original can stay as is just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 building function to collect gini impurity scores for each feature\n",
    "Because an Adaboost model is an ensemble of weighted stumps, the first step we should take is to define a function to determint best feature for the stump at whatever round we are in.\n",
    "\n",
    "Special care will be needed to distinguish continuous and categorical (binary) variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature continuous gini_score best_cutoff prob_yes0 prob_yes1\n",
      "0           temp          1   0.138889       37.95         0  0.833333\n",
      "1         nausea          0   0.269231        None  0.230769         1\n",
      "2    lumbar_pain          0   0.238095        None         0  0.714286\n",
      "3  urine_pushing          0   0.458333        None      0.25       0.5\n",
      "4    micturition          0   0.475271        None  0.344262  0.491525\n",
      "5        burning          0   0.438095        None  0.285714       0.6\n",
      "6   inflammation          0   0.468788        None  0.508197  0.322034\n",
      "37.95\n"
     ]
    }
   ],
   "source": [
    "#stump function for binary variables\n",
    "def gini(data, outcome):\n",
    "        n = len(data)\n",
    "        features = list(data.columns)\n",
    "        features.remove(outcome)\n",
    "        features.remove('weight')\n",
    "        pred = pd.DataFrame(columns = features)\n",
    "        gini_index = pd.DataFrame(columns = ['feature', \n",
    "                                             'continuous',\n",
    "                                             'gini_score',\n",
    "                                             'best_cutoff',\n",
    "                                             'prob_yes0',\n",
    "                                             'prob_yes1'\n",
    "                                            ])\n",
    "        gini_index['feature']=features \n",
    "        for feature in features:\n",
    "            if (max(data[feature]) == 1) & (min(data[feature])==0):   #rough way of sorting binary from cont. variables\n",
    "                prob_yes1 = sum(data[outcome][data[feature]==1])/len(data[data[feature]==1])\n",
    "                prob_no1 = 1 - prob_yes1\n",
    "                gini_impur1 = 1 - prob_yes1**2 - prob_no1**2\n",
    "                \n",
    "                prob_yes0 = sum(data[outcome][data[feature]==0])/len(data[data[feature]==0])\n",
    "                prob_no0 = 1 - prob_yes0\n",
    "                gini_impur0 = 1 - prob_yes0**2 - prob_no0**2\n",
    "                \n",
    "                weight_sum1 = sum(data['weight'][data[feature]==1])\n",
    "                weight_sum0 = sum(data['weight'][data[feature]==0])\n",
    "                \n",
    "                gini_index['gini_score'][gini_index['feature']==feature] = (weight_sum1*gini_impur1 + \n",
    "                                                                            weight_sum0*gini_impur0)\n",
    "                gini_index['continuous'][gini_index['feature']==feature] = 0\n",
    "                gini_index['best_cutoff'][gini_index['feature']==feature] = None\n",
    "                gini_index['prob_yes0'][gini_index['feature']==feature] = prob_yes0\n",
    "                gini_index['prob_yes1'][gini_index['feature']==feature] = prob_yes1\n",
    "                \n",
    "                \n",
    "            else: \n",
    "                sorted_feat = sorted(list(data[feature]))                                     \n",
    "                avg = []\n",
    "                for i in (range(0,len(sorted_feat)-1)):\n",
    "                    avg.append((sorted_feat[i]+sorted_feat[i+1])/2)\n",
    "                avg = sorted(list(set((avg))))         #making sure only unique figures are in list \n",
    "                lowest_gini = 1   #creating gini variable to keep track of best gini/cutoff\n",
    "                best_cutoff = 0\n",
    "                for i in (range(0,len(avg))):\n",
    "                    if min(data[feature]) == avg[i]:  # to prevent zero in denom\n",
    "                        prob_yes1 = sum(data[outcome][data[feature]> avg[i]])/len(data[data[feature]> avg[i]])\n",
    "                        prob_no1 = 1 - prob_yes1 \n",
    "                    \n",
    "                        prob_yes0 = sum(data[outcome][data[feature]<= avg[i]])/len(data[data[feature]<= avg[i]])\n",
    "                        prob_no0 = 1 - prob_yes0\n",
    "                        \n",
    "                        weight_sum1 = sum(data['weight'][data[feature] > avg[i]])\n",
    "                        weight_sum0 = sum(data['weight'][data[feature] <= avg[i]])\n",
    "\n",
    "                    else:\n",
    "                        prob_yes1 = sum(data[outcome][data[feature]>= avg[i]])/len(data[data[feature]>= avg[i]])\n",
    "                        prob_no1 = 1 - prob_yes1 \n",
    "                    \n",
    "                        prob_yes0 = sum(data[outcome][data[feature]< avg[i]])/len(data[data[feature]< avg[i]])\n",
    "                        prob_no0 = 1 - prob_yes0\n",
    "                        \n",
    "                        weight_sum1 = sum(data['weight'][data[feature] >= avg[i]])\n",
    "                        weight_sum0 = sum(data['weight'][data[feature] < avg[i]])\n",
    "                    \n",
    "                    gini_impur1 = 1 - prob_yes1**2 - prob_no1**2\n",
    "                    gini_impur0 = 1 - prob_yes0**2 - prob_no0**2\n",
    "                    gini_score = (weight_sum1*gini_impur1 + weight_sum0*gini_impur0)\n",
    "                    \n",
    "                    if  gini_score < lowest_gini:\n",
    "                        lowest_gini = gini_score\n",
    "                        best_cutoff = avg[i]\n",
    "                        best_prob_yes0 = prob_yes0\n",
    "                        best_prob_yes1 = prob_yes1 \n",
    "                        \n",
    "                gini_index['gini_score'][gini_index['feature']==feature] = lowest_gini\n",
    "                gini_index['continuous'][gini_index['feature']==feature] = 1\n",
    "                gini_index['best_cutoff'][gini_index['feature']==feature] = best_cutoff\n",
    "                gini_index['prob_yes0'][gini_index['feature']==feature] = best_prob_yes0\n",
    "                gini_index['prob_yes1'][gini_index['feature']==feature] = best_prob_yes1\n",
    "                \n",
    "        return gini_index\n",
    "                                       \n",
    "#gini_index = gini(data = df1, outcome = 'inflammation')\n",
    "gini_index = gini(data = df1, outcome = 'nephritis')\n",
    "\n",
    "\n",
    "print(gini_index)\n",
    "print(gini_index['best_cutoff'][0])\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _gini index_ table looks good! Now we need to use the data from this table to build our stump!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Building stump function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stump_cont(feature, greater_than, cutoff):  #need to create a function for continuous and binary features\n",
    "    pred = []\n",
    "    if min(feature) == cutoff:\n",
    "        if greater_than == True:\n",
    "            for feat in feature:\n",
    "                if feat <= cutoff:\n",
    "                    pred.append(0)\n",
    "                else:\n",
    "                    pred.append(1)\n",
    "        else:\n",
    "            for feat in feature:\n",
    "                if feat <= cutoff:\n",
    "                    pred.append(1)\n",
    "                else:\n",
    "                    pred.append(0)\n",
    "    else:\n",
    "        if greater_than == True:\n",
    "            for feat in feature:\n",
    "                if feat < cutoff:\n",
    "                    pred.append(0)\n",
    "                else:\n",
    "                    pred.append(1)\n",
    "        else:\n",
    "            for feat in feature:\n",
    "                if feat < cutoff:\n",
    "                    pred.append(1)\n",
    "                else:\n",
    "                    pred.append(0)\n",
    "    return pred\n",
    "\n",
    "def stump_binary(feature, yes_value):    #yes_value is 1 or 0 (whatever value yields yes prediction)\n",
    "    pred = [] \n",
    "    if yes_value == 1:\n",
    "        for feat in feature:\n",
    "            if feat == 1:       \n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "    else:\n",
    "        for feat in feature:\n",
    "            if feat == 1:\n",
    "                pred.append(0)\n",
    "            else:\n",
    "                pred.append(1)\n",
    "    return(pred)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5 making training function\n",
    "the way we're 'training' the model is to store in a table the features/parameters that 'define' the stumps of the final model as result of the training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     temp  nausea  lumbar_pain  urine_pushing  micturition  burning  \\\n",
      "0    35.5       0            1              0            0        0   \n",
      "1    35.9       0            0              1            1        1   \n",
      "2    35.9       0            1              0            0        0   \n",
      "3    36.0       0            0              1            1        1   \n",
      "4    36.0       0            1              0            0        0   \n",
      "..    ...     ...          ...            ...          ...      ...   \n",
      "115  41.4       0            1              1            0        1   \n",
      "116  41.5       0            0              0            0        0   \n",
      "117  41.5       1            1              0            1        0   \n",
      "118  41.5       0            1              1            0        1   \n",
      "119  41.5       0            1              1            0        1   \n",
      "\n",
      "     inflammation  nephritis    weight  prediction  \n",
      "0               0          0  0.000388           0  \n",
      "1               1          0  0.000388           1  \n",
      "2               0          0  0.000388           0  \n",
      "3               1          0  0.000388           1  \n",
      "4               0          0  0.000388           0  \n",
      "..            ...        ...       ...         ...  \n",
      "115             0          1  0.014873           1  \n",
      "116             0          0  0.000388           0  \n",
      "117             0          1  0.004669           0  \n",
      "118             0          1  0.014873           1  \n",
      "119             0          1  0.014873           1  \n",
      "\n",
      "[120 rows x 10 columns]\n",
      "         feature  continuous greater_than cutoff  yes_value  amount_of_say  \\\n",
      "0  urine_pushing           0         None   None          1       0.775299   \n",
      "1    micturition           0         None   None          1       1.243596   \n",
      "2  urine_pushing           0         None   None          1       1.047612   \n",
      "\n",
      "   total_error  \n",
      "0     0.175000  \n",
      "1     0.076761  \n",
      "2     0.109562  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame.copy(df) \n",
    "def train(data,outcome, stop_error = 0, max_rounds = 50):\n",
    "    total_error = 1\n",
    "    prev_total_error = 100\n",
    "    cycle_num = 0 \n",
    "    train_feat_list = [] #list for storing feature of each round\n",
    "    train_cont = [] #keeping track if above feature is continuous or not\n",
    "    train_greater_than = [] #for continuous features if greater than or less than cutoff\n",
    "    train_cutoff = []  #keeping track of cutoff for continuous variable trees\n",
    "    train_yes_value = [] #keeping track of wheter 0 or 1 predicts outcome for binary variables\n",
    "    train_amnt_of_say = [] #to keep track of amount of say for each 'stump'\n",
    "    train_total_error = []\n",
    "    \n",
    "    while (total_error > stop_error and cycle_num < max_rounds and prev_total_error > total_error):\n",
    "        gini_index = gini(data = data, outcome = outcome)\n",
    "        best_feature = list(gini_index['feature'][gini_index['gini_score'] == min(gini_index['gini_score'])])[0]\n",
    "        train_feat_list.append(best_feature)\n",
    "        predictions = []\n",
    "        new_weight = [0]*len(data)\n",
    "        for i in range(0,len(gini_index)):   #grabbing row number of best feature \n",
    "            if gini_index['feature'][i] == best_feature:\n",
    "                best = i\n",
    "                \n",
    "            \n",
    "        if gini_index['continuous'][best] == 0:\n",
    "            train_cont.append(0)\n",
    "            train_cutoff.append(None)\n",
    "            train_greater_than.append(None)\n",
    "            if gini_index['prob_yes0'][best] > gini_index['prob_yes1'][best]:\n",
    "                train_yes_value.append(0)\n",
    "                predictions = stump_binary(feature = data[best_feature], yes_value = 0)\n",
    "           \n",
    "            else:\n",
    "                train_yes_value.append(1)\n",
    "                predictions = stump_binary(feature = data[best_feature], yes_value = 1)\n",
    "        else:\n",
    "            train_cont.append(1)\n",
    "            train_cutoff.append(gini_index['best_cutoff'][best])\n",
    "            train_yes_value.append(None)\n",
    "            if gini_index['prob_yes0'][best] > gini_index['prob_yes1'][best]:\n",
    "                train_greater_than.append(False)\n",
    "                predictions = stump_cont(feature = data[best_feature], \n",
    "                                         greater_than = False, \n",
    "                                         cutoff = gini_index['best_cutoff'][best])\n",
    "            \n",
    "            else:\n",
    "                train_greater_than.append(True)\n",
    "                predictions = stump_cont(feature = data[best_feature], \n",
    "                                         greater_than = True, \n",
    "                                         cutoff = gini_index['best_cutoff'][best])\n",
    "                        \n",
    "        data['prediction'] = predictions\n",
    "        prev_total_error = total_error\n",
    "        total_error = sum(data['weight'][data['prediction']!= data[outcome]])\n",
    "        amount_of_say = (1/2)*np.log((1-total_error)/(total_error))\n",
    "        train_amnt_of_say.append(amount_of_say)\n",
    "        train_total_error.append(total_error)\n",
    "    \n",
    "    #calculate new weights:\n",
    "        for i in range(0,len(data)):\n",
    "            if data[outcome][i] != data['prediction'][i]:\n",
    "                new_weight[i] = data['weight'][i]*np.e**(amount_of_say)\n",
    "            else:\n",
    "                new_weight[i] = data['weight'][i]*np.e**(-amount_of_say)\n",
    "        data['weight'] = new_weight\n",
    "        cycle_num = cycle_num + 1\n",
    "        #return data, amount_of_say\n",
    "    \n",
    "    train_results = pd.DataFrame({\n",
    "        'feature':train_feat_list,\n",
    "        'continuous':train_cont,\n",
    "        'greater_than':train_greater_than,\n",
    "        'cutoff':train_cutoff,\n",
    "        'yes_value':train_yes_value,\n",
    "        'amount_of_say': train_amnt_of_say,\n",
    "        'total_error': train_total_error\n",
    "    })\n",
    "    return train_results\n",
    "\n",
    "results = train(data = df1 ,outcome = 'inflammation',stop_error = 0, max_rounds = 50)\n",
    "#results = train(data = df1 ,outcome = 'nephritis',stop_error = 0, max_rounds = 50)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete! percent correct =  0.825\n"
     ]
    }
   ],
   "source": [
    "def predict(train_results, data, outcome):\n",
    "    pred_after_say = [0] * len(data)\n",
    "    final_prediction = []\n",
    "    for i in range(0,len(train_results)):\n",
    "        feature = train_results['feature'][i]\n",
    "        if train_results['continuous'][i] == 1:\n",
    "            prediction = stump_cont(feature=data[feature],\n",
    "                                    greater_than = train_results['greater_than'][i],\n",
    "                                    cutoff = train_results['cutoff'][i])\n",
    "        else:\n",
    "            prediction = stump_binary(feature = data[feature], \n",
    "                                      yes_value=train_results['yes_value'][i])\n",
    "            \n",
    "        for k in range(0,len(prediction)):\n",
    "            if prediction[k] == 1:\n",
    "                pred_after_say[k] = pred_after_say[k] + train_results['amount_of_say'][i]\n",
    "            else:\n",
    "                pred_after_say[k] = pred_after_say[k] - train_results['amount_of_say'][i]\n",
    "    for pred in pred_after_say:\n",
    "        if pred >= 0:\n",
    "            final_prediction.append(1)\n",
    "        else:\n",
    "            final_prediction.append(0)\n",
    "    data['prediction'] = final_prediction\n",
    "    \n",
    "    correct = []\n",
    "    for z in range(0,len(data)):\n",
    "        if data[outcome][z] == data['prediction'][z]:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    data['correct'] = correct\n",
    "    error_rate = sum(correct)/len(data)\n",
    "    print('complete! percent correct = ',error_rate)\n",
    "    return data, error_rate\n",
    "\n",
    "df1, error_rate = predict(data= df1, train_results = results, outcome = 'inflammation')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It looks like we have the model training and predicting programs down! Let's see how well the model works when we seperate the data into a training and testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model by splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete! percent correct =  0.8526315789473684\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame.copy(df)\n",
    "import random\n",
    "\n",
    "#creating function to randomly assign observations to train/test datasets\n",
    "def split(data):\n",
    "    data['assignment'] = list(range(0,len(data)))\n",
    "    random.shuffle(data['assignment'])\n",
    "    #80 percent going to train dataset\n",
    "    data_train = pd.DataFrame.copy(data[data['assignment']<= 0.8*len(data)])\n",
    "    #20 percent going to test data set\n",
    "    data_test = pd.DataFrame.copy(data[data['assignment'] > 0.2*len(data)])\n",
    "    data_train.reset_index(drop=True, inplace = True)\n",
    "    data_test.reset_index(drop=True, inplace = True)\n",
    "   \n",
    "    return data_train, data_test\n",
    "\n",
    "\n",
    "data_train, data_test = split(df1)\n",
    "\n",
    "del data_train['assignment']\n",
    "del data_test['assignment']\n",
    "\n",
    "for col in data_train.columns:\n",
    "    data_train[col] = data_train[col].apply(lambda x: clean_data(x))\n",
    "data_train['weight'] = 1/len(data_train)\n",
    "for col in data_test.columns:\n",
    "    data_test[col] = data_test[col].apply(lambda x: clean_data(x))\n",
    "data_test['weight'] = 1/len(data_test)\n",
    "\n",
    "#training model with training dataset \n",
    "train_results = train(data = data_train, outcome = 'inflammation')\n",
    "\n",
    "data_final, error_rate = predict(train_results = train_results, data = data_test, outcome = 'inflammation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
